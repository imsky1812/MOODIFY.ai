# MOODIFY.ai â€” Multimodal AI Wellbeing Assistant

**MOODIFY.ai** is an AI-powered emotional wellbeing companion designed to help students express, understand, and manage their emotions through natural conversation.

Unlike a traditional chatbot, Moodify behaves like a supportive digital companion.
It combines **conversational AI, emotion detection, voice interaction, and real-time facial expression analysis** into a single interactive application.

---

## ðŸŽ¯ Project Objective

The goal of this project is to create a human-like AI companion that:

* Provides emotionally supportive conversations
* Detects the userâ€™s emotional state
* Encourages reflection and self-expression
* Creates a calming and engaging wellness environment
* Demonstrates real-time multimodal AI interaction

---

## ðŸ§  Key Features

### ðŸ’¬ Conversational AI Companion

* Human-like empathetic conversations
* Context-aware responses
* Personalized interaction personality ("Moodify")

### ðŸ“Š Emotion & Wellbeing Analysis

* Text emotion detection (happy, sad, anxious, neutral)
* Real-time wellbeing score updates
* Emotion tracking during conversations

### ðŸŽ¤ Voice Assistant

* Speech-to-Text interaction
* Continuous listening mode
* Text-to-Speech AI replies

### ðŸ“· Facial Emotion Recognition

* Real-time webcam emotion detection
* On-demand camera activation
* Powered by computer vision

### ðŸ–¥ï¸ Interactive UI

* Messaging-style chat interface
* Typing indicator animation
* Animated gradient background
* Glassmorphism design

---

## ðŸ§° Technology Stack

### Backend

* Python 3.10
* FastAPI
* Uvicorn Server
* Groq API (LLaMA-3.3-70B conversational model)

### Frontend

* HTML5
* CSS3 (Glassmorphism UI)
* JavaScript (DOM + Fetch API)

### AI / Machine Learning

* DeepFace
* TensorFlow
* OpenCV
* SpeechRecognition
* PyAudio
* gTTS (Text-to-Speech)
* Groq Python SDK

---

## ðŸ—ï¸ System Architecture

Frontend â†’ FastAPI Server â†’ Emotion Detection â†’ LLM Response â†’ UI Display

The frontend sends user input to the FastAPI backend.
The backend analyzes emotion, sends the message to the LLM, generates a response, and updates the wellbeing score in real time. 

---

## ðŸ”„ Application Workflow

1. AI greets the user
2. User sends a message
3. Emotion is detected from text
4. LLM generates an empathetic response
5. Wellbeing score updates
6. User can switch to voice mode
7. User can enable live camera emotion detection

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/imsky1812/MOODIFY.ai.git
cd MOODIFY.ai
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Create `.env` file

Create a file named `.env` and add:

```
GROQ_API_KEY=your_api_key_here
```

### 4ï¸âƒ£ Run the application

```bash
uvicorn app:app --reload
```

Open browser:

```
http://127.0.0.1:8000
```

---

## ðŸ§ª Final Capabilities

* Emotional conversational AI
* Wellbeing score monitoring
* Voice interaction
* Facial emotion detection
* Dynamic UI experience
* Real-time response generation

---

## ðŸš§ Challenges Faced

During development several issues were encountered:

* API quota & key validation problems
* TensorFlow compatibility errors
* DeepFace model loading failures
* Audio recording format issues
* Server port conflicts

These were resolved using fallback responses, server warm-up, and improved error handling to ensure demo stability. 

---

## ðŸ“Œ Conclusion

MOODIFY.ai demonstrates how AI can go beyond automation and act as a supportive digital companion.
By combining conversational intelligence, voice communication, and facial emotion recognition, the project highlights the role of human-centered AI in mental wellness and interactive computing. 

---

## ðŸ‘¨â€ðŸ’» Author

**Sarvesh Kumar Yadav**

---

## â­ Future Improvements

* Mobile app integration
* Mood history dashboard
* Music recommendation based on mood
* User accounts & personalization
* Therapy resource suggestions

---

> *Moodify is not a medical tool and is intended only for emotional support and interaction.*
